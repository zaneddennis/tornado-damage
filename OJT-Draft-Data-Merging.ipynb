{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package import cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull all storm events (2008-2018)\n",
    "# Source URL: https://www1.ncdc.noaa.gov/pub/data/swdi/stormevents/csvfiles/\n",
    "\n",
    "storms = pd.DataFrame()\n",
    "years = ['2009_c20180718', '2010_c20170726', '2011_c20180718', '2012_c20170519', \n",
    "         '2013_c20170519', '2014_c20180718', '2015_c20180525', '2016_c20180718',\n",
    "         '2017_c20181017', '2018_c20181017']\n",
    "\n",
    "for year in years:\n",
    "    storms = storms.append(pd.read_csv('/users/Orion/Downloads/StormEvents_details-ftp_v1.0_d'\n",
    "                                       +str(year)+'.csv.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['TEXAS', 'OREGON', 'KENTUCKY', 'LOUISIANA', 'VIRGINIA', 'GEORGIA',\n",
       "       'ALABAMA', 'MISSOURI', 'ILLINOIS', 'FLORIDA', 'NORTH CAROLINA',\n",
       "       'TENNESSEE', 'MISSISSIPPI', 'INDIANA', 'KANSAS', 'OKLAHOMA',\n",
       "       'COLORADO', 'IDAHO', 'NEBRASKA', 'SOUTH CAROLINA', 'VERMONT',\n",
       "       'ARKANSAS', 'IOWA', 'MARYLAND', 'NEW YORK', 'OHIO', 'NORTH DAKOTA',\n",
       "       'HAWAII', 'SOUTH DAKOTA', 'WYOMING', 'MINNESOTA', 'ARIZONA',\n",
       "       'MAINE', 'MICHIGAN', 'UTAH', 'CALIFORNIA', 'PENNSYLVANIA',\n",
       "       'WISCONSIN', 'NEW MEXICO', 'WASHINGTON', 'CONNECTICUT', 'MONTANA',\n",
       "       'NEVADA', 'NEW JERSEY', 'PUERTO RICO', 'WEST VIRGINIA',\n",
       "       'NEW HAMPSHIRE', 'DELAWARE', 'MASSACHUSETTS', 'RHODE ISLAND',\n",
       "       'DISTRICT OF COLUMBIA'], dtype=object)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out non-tornado events\n",
    "\n",
    "tornadoes = storms.loc[storms['EVENT_TYPE'] == 'Tornado']\n",
    "\n",
    "# Check states where tornadoes have occurred (to help target additional data mining)\n",
    "\n",
    "tornadoes['STATE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull income data (2016)\n",
    "# Source URL: https://www.census.gov/data/datasets/2016/demo/saipe/2016-state-and-county.html\n",
    "\n",
    "income = pd.read_csv('/users/Orion/Downloads/est16all.csv', header=3)\n",
    "\n",
    "# Clean income data to match 'State FIPS Code' and 'Name' formatting \n",
    "# with tornado 'STATE_FIPS' and 'CZ_NAME' data\n",
    "\n",
    "income['State FIPS Code'] = income['State FIPS Code'].astype(int)\n",
    "income = income[~income['Name'].str.contains(\"County\") == False]\n",
    "income['Name'].replace(regex=True,inplace=True,to_replace=r' County',value=r'')\n",
    "income['Name'] = income['Name'].str.upper()\n",
    "\n",
    "# Merge income and tornado dataframes on FIPS and county columns (per above)\n",
    "\n",
    "tornadoes_with_income = pd.merge(tornadoes, income, how='left', \n",
    "                                 left_on=['STATE_FIPS','CZ_NAME'], \n",
    "                                 right_on=['State FIPS Code','Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull population density data (2010)\n",
    "# Source URL: https://factfinder.census.gov/faces/tableservices/jsf/pages/productview.xhtml?src=bkmk \n",
    "# Note: URL above wasn't working for Orion -- used .CSV file emailed by Sree\n",
    "\n",
    "density = pd.read_csv('/users/Orion/Downloads/Population_Density.csv', encoding='cp1252', header=1)\n",
    "\n",
    "# Clean density data to match 'Geographic area' and Geographic area.1' formatting \n",
    "# with tornado+income 'STATE' and 'CZ_NAME' data\n",
    "\n",
    "density = density[~density['Geographic area.1'].str.contains(\"County\") == False]\n",
    "density['Geographic area.1'].replace(regex=True,inplace=True,to_replace=r' County',value=r'')\n",
    "density['Geographic area.1'] = density['Geographic area.1'].str.upper()\n",
    "density['Geographic area'].replace(regex=True,inplace=True,to_replace=r'United States - ',value=r'')\n",
    "density['Geographic area'] = [x.split(' -')[0] for x in density['Geographic area']]\n",
    "density['Geographic area'] = density['Geographic area'].str.upper()\n",
    "\n",
    "# Merge density and tornado+income dataframes on state and county columns (per above)\n",
    "\n",
    "tornadoes_with_income_with_density = pd.merge(tornadoes_with_income, density, how='left',\n",
    "                                              left_on=['STATE','CZ_NAME'], \n",
    "                                              right_on=['Geographic area','Geographic area.1'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
